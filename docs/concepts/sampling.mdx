---
title: "サンプリング"
description: "サーバーがLLMからの補完をクライアント経由でリクエストできる機能"
---

サンプリングは、セキュリティとプライバシーを維持しながら洗練されたエージェント的な動作を可能にする、強力なMCP機能です。サーバーがクライアントを通じてLLMの補完をリクエストできます。

<Info>
  このMCP機能は、Claude Desktopクライアントではまだサポートされていません。
</Info>

## サンプリングの仕組み

サンプリングのフローは以下の手順で行われます:

1. サーバーがクライアントに`sampling/createMessage`リクエストを送信
2. クライアントがリクエストを確認し、必要に応じて修正
3. クライアントがLLMからサンプリング
4. クライアントが補完結果を確認
5. クライアントが結果をサーバーに返送

この人間が介入する設計により、ユーザーはLLMが受け取る情報と生成する内容を制御できます。

## メッセージ形式

サンプリングリクエストは標準化されたメッセージ形式を使用します:

```typescript
{
  messages: [
    {
      role: "user" | "assistant",
      content: {
        type: "text" | "image",

        // テキストの場合:
        text?: string,

        // 画像の場合:
        data?: string,             // base64エンコード
        mimeType?: string
      }
    }
  ],
  modelPreferences?: {
    hints?: [{
      name?: string                // 推奨モデル名/ファミリー
    }],
    costPriority?: number,         // 0-1, コスト最小化の重要度
    speedPriority?: number,        // 0-1, 低遅延の重要度
    intelligencePriority?: number  // 0-1, 能力の重要度
  },
  systemPrompt?: string,
  includeContext?: "none" | "thisServer" | "allServers",
  temperature?: number,
  maxTokens: number,
  stopSequences?: string[],
  metadata?: Record<string, unknown>
}
```

## リクエストパラメータ

### メッセージ

`messages`配列にはLLMに送信する会話履歴が含まれます。各メッセージには以下があります:

- `role`: "user"または"assistant"
- `content`: メッセージ内容（以下いずれか）:
  - `text`フィールドを持つテキスト内容
  - `data`（base64）と`mimeType`フィールドを持つ画像内容

### モデル設定

`modelPreferences`オブジェクトでサーバーはモデル選択の設定を指定できます:

- `hints`: 適切なモデル選択のためのモデル名候補の配列:
  - `name`: 完全または部分的なモデル名にマッチする文字列（例: "claude-3", "sonnet"）
  - クライアントはヒントを異なるプロバイダーの同等モデルにマッピング可能
  - 複数のヒントは優先順位で評価

- 優先度値（0-1で正規化）:
  - `costPriority`: コスト最小化の重要度
  - `speedPriority`: 低遅延応答の重要度
  - `intelligencePriority`: 高度なモデル能力の重要度

クライアントはこれらの設定と利用可能なモデルに基づいて最終的なモデルを選択します。

### システムプロンプト

オプションの`systemPrompt`フィールドで、サーバーは特定のシステムプロンプトをリクエストできます。クライアントはこれを変更または無視できます。

### コンテキスト包含

`includeContext`パラメータは含めるMCPコンテキストを指定します:

- `"none"`: 追加コンテキストなし
- `"thisServer"`: リクエスト元サーバーのコンテキストを含む
- `"allServers"`: 接続中の全MCPサーバーのコンテキストを含む

実際に含まれるコンテキストはクライアントが制御します。

### サンプリングパラメータ

LLMサンプリングを微調整するパラメータ:

- `temperature`: ランダム性を制御（0.0から1.0）
- `maxTokens`: 生成する最大トークン数
- `stopSequences`: 生成を停止するシーケンスの配列
- `metadata`: プロバイダー固有の追加パラメータ

## レスポンス形式

クライアントは補完結果を返します:

```typescript
{
  model: string,  // 使用されたモデル名  stopReason?: "endTurn" | "stopSequence" | "maxTokens" | string,
  role: "user" | "assistant",
  content: {
    type: "text" | "image",
    text?: string,
    data?: string,
    mimeType?: string
  }
}
```

## リクエスト例

クライアントへのサンプリングリクエスト例:

```json
{
  "method": "sampling/createMessage",
  "params": {
    "messages": [
      {
        "role": "user",
        "content": {
          "type": "text",
          "text": "What files are in the current directory?"
        }
      }
    ],
    "systemPrompt": "You are a helpful file system assistant.",
    "includeContext": "thisServer",
    "maxTokens": 100
  }
}
```

## ベストプラクティス

サンプリング実装時のベストプラクティス:

1. 常に明確で構造化されたプロンプトを提供
2. テキストと画像の両方のコンテンツを適切に処理
3. 適切なトークン制限を設定
4. `includeContext`で関連コンテキストを含める
5. 使用前にレスポンスを検証
6. エラーを適切に処理
7. サンプリングリクエストのレート制限を考慮
8. 期待されるサンプリング動作を文書化
9. 様々なモデルパラメータでテスト
10. サンプリングコストを監視

## 人間の制御

サンプリングは人間の監視を考慮して設計されています:

### プロンプトについて

- クライアントはユーザーに提案プロンプトを表示
- ユーザーはプロンプトを変更または拒否可能
- システムプロンプトはフィルタリングまたは変更可能
- コンテキスト包含はクライアントが制御

### 補完について

- クライアントはユーザーに補完結果を表示
- ユーザーは補完を変更または拒否可能
- クライアントは補完をフィルタリングまたは変更可能
- 使用モデルはユーザーが制御

## セキュリティ考慮事項

サンプリング実装時のセキュリティ考慮事項:

- 全てのメッセージ内容を検証
- 機密情報をサニタイズ
- 適切なレート制限を実装
- サンプリング使用状況を監視
- 転送中のデータを暗号化
- ユーザーデータのプライバシーを処理
- サンプリングリクエストを監査
- コスト露出を制御
- タイムアウトを実装
- モデルエラーを適切に処理

## 一般的なパターン

### エージェント的なワークフロー

サンプリングにより可能なエージェント的パターン:

- リソースの読み取りと分析
- コンテキストに基づく意思決定
- 構造化データの生成
- マルチステップタスクの処理
- インタラクティブな支援の提供

### コンテキスト管理

コンテキストのベストプラクティス:

- 必要な最小限のコンテキストをリクエスト
- コンテキストを明確に構造化
- コンテキストサイズ制限を処理
- 必要に応じてコンテキストを更新
- 古いコンテキストをクリーンアップ

### エラー処理

堅牢なエラー処理:

- サンプリング失敗を捕捉
- タイムアウトエラーを処理
- レート制限を管理
- レスポンスを検証
- フォールバック動作を提供
- エラーを適切にログ記録

## 制限事項

以下の制限事項に注意:

- サンプリングはクライアントの能力に依存
- ユーザーがサンプリング動作を制御
- コンテキストサイズに制限
- レート制限が適用される場合あり
- コストを考慮する必要あり
- モデルの可用性は様々
- 応答時間は変動
- 全てのコンテンツタイプがサポートされているわけではない
